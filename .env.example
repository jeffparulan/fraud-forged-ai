# ============================================================
# FraudForge AI - Environment Variables Template
# ============================================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to Git - it's in .gitignore for security
# ============================================================

# ============================================================
# HUGGING FACE (REQUIRED)
# ============================================================
# Get your token from: https://huggingface.co/settings/tokens
# Used for: Finance-Llama3-8B, Nemotron Nano 12B v2 (Nebius)
HUGGINGFACE_API_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ============================================================
# OPENROUTER (OPTIONAL - Fallback for Nemotron)
# ============================================================
# Get your key from: https://openrouter.ai/keys
# Used as fallback if HF is rate limited
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Optional OpenRouter metadata
OPENROUTER_SITE_URL=https://fraudforge.local
OPENROUTER_APP_NAME=FraudForge AI

# ============================================================
# PINECONE (REQUIRED for RAG)
# ============================================================
# Get your API key from: https://app.pinecone.io/
# Create a free Starter index (1 pod, 100K vectors)
PINECONE_API_KEY=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
PINECONE_INDEX_NAME=fraudforge-master
PINECONE_HOST=https://fraudforge-master-xxxxxx.svc.xxxx-xxxx-xxxx.pinecone.io

# ============================================================
# GOOGLE VERTEX AI (OPTIONAL - for MedGemma)
# ============================================================
GCP_PROJECT_ID=your-gcp-project-id
GCP_API_KEY=your-gcp-api-key

# ============================================================
# FRONTEND CONFIGURATION
# ============================================================
# API URL - for local dev, use localhost
# For production, this is set automatically by Cloud Run
NEXT_PUBLIC_API_URL=http://localhost:8000

# ============================================================
# BACKEND CONFIGURATION
# ============================================================
# Port for FastAPI (Cloud Run uses 8080)
PORT=8080

# Python environment
PYTHONUNBUFFERED=1

# Kill switch (for emergency shutdown in production)
KILL_SWITCH_ENABLED=false

# ============================================================
# TERRAFORM DEPLOYMENT (for GCP deployment)
# ============================================================
# Copy these to infrastructure/terraform.tfvars
# See infrastructure/terraform.tfvars.example for details

# TF_VAR_project_id=your-gcp-project-id
# TF_VAR_region=us-central1
# TF_VAR_huggingface_token=${HUGGINGFACE_API_TOKEN}
# TF_VAR_openrouter_key=${OPENROUTER_API_KEY}
# TF_VAR_pinecone_api_key=${PINECONE_API_KEY}
# TF_VAR_pinecone_index_name=${PINECONE_INDEX_NAME}
# TF_VAR_pinecone_host=${PINECONE_HOST}
# ============================================================
# NOTES
# ============================================================
# 1. FREE TIER LIMITS:
#    - HuggingFace: ~100-300 requests/hour (free)
#    - OpenRouter: Limited by provider quotas (free tier)
#    - Pinecone: 100K vectors, 1 pod (free Starter plan)
#    - GCP Cloud Run: 2M requests/month (free tier)
#
# 2. REQUIRED FOR LOCAL DEV:
#    - HUGGINGFACE_API_TOKEN (required)
#    - PINECONE_API_KEY + INDEX_NAME + HOST (required)
#    - OPENROUTER_API_KEY (optional, but recommended)
#
# 3. REQUIRED FOR GCP DEPLOYMENT:
#    - All of the above
#    - GCP_PROJECT_ID (your GCP project)
#    - terraform.tfvars (see infrastructure/terraform.tfvars.example)
#
# 4. SECURITY:
#    - Never commit .env to Git
#    - Rotate API keys regularly
#    - Use Secret Manager for production
#    - Enable 2FA on all accounts
# ============================================================
